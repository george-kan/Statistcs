---
title: Parametric statistical models
author: George
date: '2020-08-25'
slug: first-post
categories: []
tags:
  - plot
output:
  html_document:
    mathjax: local
    self_contained: false
---

```{r echo = F, warning = F}
library(data.table)
library(ggplot2)
theme_set(theme_light())
```

## _Statistical models, what are they?_

_Statistical models are a way of approximating reality using probability distributions._    
Let's say that we want to analyse the hourly number of customers coming to a shop from 9-5 in order to assess how many people are needed to work. To that extent, we measure the number of customers that we observed in a day and the results looked like this:

|Time interval|Customers|
|:----:|:-----:|
|9-10|  3  |
|10-11|  2  |
|11-12|  1  |
|12-13|  3  |
|13-14|  2  |
|14-15|  1  |
|15-16|  0  |
|16-17|  3  |

Our goal is to be able to explain reality using probabilities. Ideally we would like to be able to answer questions such as:  
1. _What is the probability that we will get more than 4 customers in any one hour interval of the day?_  
2. _How many customers would we expect on average to get in a day?_  
3. _Which time intervals have the lowest traffic on average?_

Since we want to use probabilities, the first thing we need is a probability distribution that could be used in order to describe what we observe in reality. There are numerous probability distributions that we can choose from and none of them is the one that fully describes reality. But we still have to try to find one that seems reasonable given our data.

What do we mean by reasonable? 
Well in our particular example of the shop above, it would be good if our distribution fulfilled the following properties:  
- No negative values (Customers in an hour cannot be negative)  
- Only integer values allowed (Customers in an hour have to be an integer number)  
- Arrivals are independent of each other

But in order to narrow down our search more we have to go one step beyond and make certain assumptions. Some of those could be:  
- Do we think that all hours in a day follow the same probability distribution? Or are certain times more popular than others?  
- Do certain days have more customers than others and therefore the hourly probability distribution for those days should be different?

These are very reasonable questions to ask about our model of reality. And depending on the answer (which again depends on the data we observe) we have to adapt our probability distribution accordingly. This could be done for example by adding extra parameters or modeling some days separately. 

Coming back to our example, a reasonable distribution for customers in an hour is a [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution). How does a Poisson distribution look like?

```{r echo = F}

poisson_plot = data.table(x = 0:10)
poisson_plot =poisson_plot[, list(x=rep(x,each=6), lambda= 1:6)]
poisson_plot[, Probability := dpois(x, lambda)]

ggplot(poisson_plot, aes(x, Probability, color = factor(lambda))) +
  geom_point(size = 3) +
  scale_color_discrete(guide = F) +
  scale_x_continuous(breaks = 0:10) +
  facet_wrap(paste0("Lambda = ",lambda) ~ .) +
  labs(x = "Customers", title = "Examples of Poisson distributions") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        strip.text = element_text(colour = 'black'),
        text = element_text(size=15))

```
As can be seen from the chart the Poisson distribution changes depending on the value of lambda that we select. For example, it is far more likely that we are going to have 0 or 1 customer in an hour if lambda equals 1 than if lambda equals 6.  
Therefore, we can say that if our assumptions are correct, a good approximation for modeling the reality of customer arrivals is a Poisson distribution with a certain specific parameter lambda.


Which brings us to the more formal definition of a statistical model:

A statistical model is thought of as a pair ${\left(S, \{ P_\theta \} _{\theta \in \Theta }\right)}$  
The components of the pair are:  

1. $S$ is the sample space, as in a set that contains all possible observations we could make. In the shop example $S$ would be the set of all positive integers [$N^0$](https://en.wikipedia.org/wiki/Natural_number#Notation)

2. ${P}$ is the family of all probability distributions on $S$. In our example, these are all the Poisson distributions on the sample data.

3. $\theta$ is the parameter of our distribution. In our case this parameter is **lambda**  

4. ${\Theta}$ is the parameter space. Basically where does our parameter(s) live? In the shop example, since we have a Poisson distribution lambda can only be positive and therefore $\Theta = (0, +\infty)$ 

### _Desirable properties of statistical models_

#### Well specified

_A model is well specified if for a certain value of the parameter $\theta$ we can obtain the true distribution (the distribution that governs reality)._

This means that if we have the space of all probability distributions (an infinite space which contains any distribution you can imagine) and we narrow it down to a family of distributions $P_{\theta \in \Theta}$ (green rectangle), then our model is well specified if the true distribution $\color{blue}P$ that is generating our data is included in that family (in the green rectangle).
```{r echo=F}
plot(c(100, 200), c(300, 450), type= "n", main = "Space of all probability distributions", xlab = "", ylab = "", xaxt = "n", yaxt = "n")
rect(100, 300, 125, 350, col = "lightgreen") # transparent
text(148, 370, expression(P[theta %in% Theta]), cex=1.5)
arrows(126, 352, 140, 365, code = 1)
points(120, 310, pch = 19)
text(120, 320, expression(P), cex = 1.5, col = "blue")
```
In our shop example, $P_{\theta \in \Theta}$ are all the possible Poisson distributions and if our model is well specified the true distribution that governs the arrival of customers in our shop is a Poisson distribution with a certain parameter lambda.

#### Identifiable

_A model is identifiable if there is a one-to-one relationship between $\theta$ and $P_\theta$._  
In simple terms, what this means is this:
If you are given that $P_{\theta_1} = P_{\theta_2}$, then $\theta_1 = \theta_2$

By extention this also means that if you are given $\theta_1$ and $\theta_2$, with $\theta_1 <> \theta_2$, then $P_{\theta_1} <> P_{\theta_2}$   

